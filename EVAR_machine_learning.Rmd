---
title: "EVAR_machine_learning"
author: "Joshua Geiger and Mohammed Mehdi Shahid"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
editor_options:
  markdown:
    wrap: 72
---

Update! Dataset is done, and ready to go!

Hey Mehdi,

Thanks for getting this started. The rds dataset that i provided is a
pretty good clean start. The variable that we will be attempting to
predict is sac_regression_12m_cat. This variable states weather The
Shins aortic aneurysms sac regressed states stable or increased in size
at the one-year mark. I had to do a bit of reformatting of all of the
data in order to calculate this appropriately given the variability in
the CT scan dates and sizes. I am confident this variable is accurate at
the moment.

There are variables within the data set that are incomplete and perhaps
chart reviewing to finish collecting some of this data will be
important. Particularly the first couple of patients were recorded
before all of the VQI variables were established and so there is some
missing data there. Additionaly, the last 20 some patients I recently
extracted from the VQI and so variables we manually extracted from the
chart have not be collected yet. Baqir and I can help out with this.
Baqir has also submitted a request for the lab values for these last 20
some patients. In addition we will be obtaining dates of death for the
entire data set. I think doing an additional analysis using similar
methods on survival, either length of survival or survival at 5 years
will also be interesting.


02/26 Meeting (Baqir, Mehdi and Josh)
- Josh to check missing sac_regression data
- Reorder nominal and ordinal variables
- Remove some variables like physician
- Use one-year and 5 year as outcomes too

## SETUP

### Install Packages

```{r setup}
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")

#Install relevant libraries using pacman (i.e. package manager)

# Use pacman to load add-on packages as desired
pacman::p_load(pacman, 
               # essentials
               tidyverse, rio, caret,finalfit,
               
               #plots
               ggplot2, mice, missRanger, gridExtra,
               
               #machine learning
               pROC, xgboost, ranger, naivebayes, e1071, nnet, glmnet,
               
               # extras
               forcats, janitor, explore, caTools, Metrics, VIM, car)
```




### Load data

```{r load-data}
#Sourcedir for Mehdi
EVARSourcedir <- "~/Desktop/EVAR/EVAR_reintervention_04_11_2024.rds"

#Sourcedir for Josh
#EVARSourcedir <- "data/EVAR_cleaned_filtered_12_23_23.rds"

EVAR <- readRDS(EVARSourcedir)
```



### Correct Errors

```{r correct-errors}
#Correct errors in the EVAR dataframe
EVAR[ which(EVAR$primprocid == 798089), "height_cm"] <- 188.00
EVAR[ which(EVAR$primprocid == 798089), "bmi"] <- 32.7
```


## CLEANING DATA

Let's get a glimpse of the dataframe as it is now
Finalfit is a great package to do this
ff_glimpse() returns a list containing dataframes for continous and categorical vars
It gives mean, min, max, and na_counts and na_percent

```{r EVAR-ff-glimpse}
EVAR_glimpse <- ff_glimpse(EVAR)
EVAR_preprocess <- EVAR
```


Remove unnecessary or uninformative columns

```{r}
EVAR_preprocess$zip_postal_code <- NULL
EVAR_preprocess$dysrhythmia <- NULL
EVAR_preprocess$primprocid <- NULL

#removing smoking quit date as I don't know how to work with this data type with ML for now....
#I created a years since quite smoking variable and removed the date. 
#EVAR_preprocess$quit_smoking_date <- NULL
```

### Data Types

Change column data types

When converting to factors make sure the ordering makes sense. For
example factor levels for smoking might look something like never, quit,
current. Changing the order to something like quit, current, never,
could very much mess with the analysis if these factors are considered
as ordinal variables, which they often are. can use fct_relevel to
change these

```{r}
# Convert all character columns to factors
EVAR_preprocess <- EVAR_preprocess %>%
  mutate_if(is.character, as.factor) %>%
  # conver to factor if unique values are less or equal to 5
  mutate_if(function(x) is.numeric(x) && n_distinct(x) <= 5, as.factor)

```

#### No and Yes variables

'No' and 'Yes' are mostly nominal, but for consistency, we can reorder
all factor variables with 'No' and 'Yes' to be No for level 1 and Yes
for level 2

```{r}
# Identify factor variables with 'No' and 'Yes' levels
no_yes_factors <- EVAR_preprocess %>%
  select(where(is.factor)) %>%
  keep(~ length(levels(.)) == 2 && all(c("No", "Yes") %in% levels(.)))

# Reorder the levels for 'No' as level 1 and 'Yes' as level 2
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(across(all_of(names(no_yes_factors)), ~fct_relevel(., "No", "Yes")))

```

#### Releveling data

Determine which factors need to be releveled

```{r factor-variables}
# To make sure ordering of each factor variable makes sense, we must investigate each to determine which need to reordered with fct_relevel
# Extract information about factor variables
factorVars_info <- lapply(names(EVAR_preprocess), function(column_name) {
  column <- EVAR_preprocess[[column_name]]
  
  if (is.factor(column)) {
    levels_info <- levels(column)
    return(list(
      variable_name = column_name,
      num_levels = length(levels_info),
      levels = levels_info
    ))
  } else {
    return(NULL)  # Not a factor variable
  }
})

# Remove NULL elements (non-factor variables) from the list
factorVars_info <- factorVars_info[sapply(factorVars_info, function(x) !is.null(x))]

# Print the information
for (info in factorVars_info) {
  cat("Variable Name:", info$variable_name, "\n")
  cat("Number of Levels:", info$num_levels, "\n")
  cat("Levels:", paste(info$levels, collapse = "; "), "\n\n")
}
```

Based on the above output, we choose which variables to reorder and also
correct some errors within the dataset.

#### Convert to numeric

Correcting some errors - aortic_graft_length_1

Convert to num:
aortic_graft_length_1, right_iliac_graft_diameter_1, right_iliac_graft_length_1, left_iliac_graft_length_1, renal_svs, age_svs

```{r correct-errors}
# aortic_graft_length_1 needs some error fixes and then convert to num
# Here we convert one of the errors from 90-30 to 90. Need to check if this is okay....

EVAR_preprocess <- EVAR_preprocess %>%
  mutate(
    # aortic_graft_length_1
    aortic_graft_length_1 = as.character(aortic_graft_length_1), 
    aortic_graft_length_1 = if_else(aortic_graft_length_1 == "90-30", 
                                    "90", aortic_graft_length_1),
    
    # right_iliac_graft_diameter_1
    right_iliac_graft_diameter_1 = as.character(right_iliac_graft_diameter_1), 
    right_iliac_graft_diameter_1 = if_else(right_iliac_graft_diameter_1 == "16-14.5", 
                                           "16", right_iliac_graft_diameter_1),
    
    #right_iliac_graft_length_1
    right_iliac_graft_length_1 = as.character(right_iliac_graft_length_1), 
    right_iliac_graft_length_1 = if_else(right_iliac_graft_length_1 == "Other", 
                                           NA, right_iliac_graft_length_1),
    
    # left_iliac_graft_length_1
    left_iliac_graft_length_1 = as.character(left_iliac_graft_length_1), 
    left_iliac_graft_length_1 = if_else(left_iliac_graft_length_1 == "Other", 
                                           NA, left_iliac_graft_length_1)
    )

EVAR_preprocess <- EVAR_preprocess %>%
  mutate(right_iliac_graft_diameter_1 = as.numeric(right_iliac_graft_diameter_1),
         right_iliac_graft_length_1 = as.numeric(right_iliac_graft_length_1),
         aortic_graft_length_1 = as.numeric(aortic_graft_length_1),
         left_iliac_graft_length_1 = as.numeric(left_iliac_graft_length_1),
         # age_svs\
         age_svs = as.numeric(age_svs),
         # renal_svs
         renal_svs = as.numeric(renal_svs)
         )

```

#### Reorder factors
Variables that need to be reordered: 

dysrhy, cvd, prior_chf, copd, diabetes, smoking, 
pre_op_p2y12_antagonist, pre_op_beta_blocker, pre_op_chronic_anticoagulant, ejection_fraction, 
aorta_neck_angle, neck_aaa_angle,
anesthesia, prbc_in_or_or_preop, proximal_aortic_extensions, number_right, number_right
ltf_statin, ltf_beta_blocker, ltf_ace_inhibitor_arb, right_iliac_endpoint, left_iliac_endpoint

```{r reorder-factors}

# dysrhy
EVAR_preprocess$dysrhy <- fct_relevel(EVAR_preprocess$dysrhy, "No", "Yes, atrial", "Other") #N

#cvd
EVAR_preprocess$cvd <- fct_relevel(EVAR_preprocess$cvd,"None","Hx stroke, asymptomatic", "Hx stroke, minor deficit", "Hx stroke, major deficit") #O

#prior_chf
EVAR_preprocess$prior_chf <- fct_relevel(EVAR_preprocess$prior_chf,"None","Asymp, hx CHF", "Mild", "Moderate") #O

#copd
EVAR_preprocess$copd <- fct_relevel(EVAR_preprocess$copd,"No","Not treated","On meds", "On home oxygen") #O

#diabetes
EVAR_preprocess$diabetes <- fct_relevel(EVAR_preprocess$diabetes,"None","Diet","Non-insulin meds", "Insulin") #O

#smoking
EVAR_preprocess$smoking <- fct_relevel(EVAR_preprocess$smoking,"Never", "Prior", "Current") #O


#pre_op_p2y12_antagonist
EVAR_preprocess$pre_op_p2y12_antagonist <- fct_relevel(EVAR_preprocess$pre_op_p2y12_antagonist, "None", "No", "Clopidogrel","Ticagrelor", "Prasugrel" ) # convert to binary (yes/no)

#pre_op_beta_blocker
EVAR_preprocess$pre_op_beta_blocker <- fct_relevel(EVAR_preprocess$pre_op_beta_blocker, "No", "No, for medical reason", "Pre-op 1-30 days", "Chronic > 30 days") # convert to binary (yes/no) 

#pre_op_chronic_anticoagulant
EVAR_preprocess$pre_op_chronic_anticoagulant <- fct_relevel(EVAR_preprocess$pre_op_chronic_anticoagulant, "None", "No, for medical reason", "Other", "Rivaroxaban", "Warfarin", "Dabigatran") # convert to binary (yes/no)

#ejection_fraction
EVAR_preprocess$ejection_fraction <- fct_relevel(EVAR_preprocess$ejection_fraction,"Not done", "Unknown", "<30%", "30-50%", ">50%") # impute unknowns. #O



#aorta_neck_angle
EVAR_preprocess$aorta_neck_angle <- fct_relevel(EVAR_preprocess$aorta_neck_angle, "< 45 Degrees", "45-60 Degrees", "61-75 Degrees", "76-90 Degrees", "> 90 Degrees") #O
#neck_aaa_angle
EVAR_preprocess$neck_aaa_angle <- fct_relevel(EVAR_preprocess$neck_aaa_angle,"< 45 Degrees", "45-60 Degrees", "61-75 Degrees", "76-90 Degrees", "> 90 Degrees") #O


EVAR_preprocess$iliac_aneurysm <- fct_relevel(EVAR_preprocess$iliac_aneurysm, "No", "Left", "Right", "Unilateral", "Bilateral")
EVAR_preprocess$iliac_aneurysm <- fct_collapse(EVAR_preprocess$iliac_aneurysm, "Unilateral" = c("Left", "Right", "Unilateral"))


#anesthesia
EVAR_preprocess$anesthesia <- fct_relevel(EVAR_preprocess$anesthesia,"Local", "Regional", "General") #N

EVAR_preprocess$prbc_in_or_or_preop <- fct_relevel(EVAR_preprocess$prbc_in_or_or_preop, "0", "1", "2", "3", "4") # remove

#proximal_aortic_extensions
EVAR_preprocess$proximal_aortic_extensions <- fct_relevel(EVAR_preprocess$proximal_aortic_extensions, "None", "1", "2", "3") #O. Convert none to 0

#number_right
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(number_right = fct_relevel(number_right,"None", "1", "2", "3")) %>%
  mutate(number_right = fct_recode(number_right, "0" = "None")) %>%
  mutate(number_right = as.numeric(as.character(number_right))) #O

# number_left
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(number_left = fct_relevel(number_left,"None", "1", "2", "3")) %>%
  mutate(number_left = fct_recode(number_left, "0" = "None")) %>%
  mutate(number_left = as.numeric(as.character(number_left))) #O

# ltf_statin
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(ltf_statin = as.character(ltf_statin)) %>%
  mutate(ltf_statin = factor(na_if(ltf_statin, ""), levels = c("Yes", "No, for medical reason", "No", "Non-compliant"))) # yes no # N

# ltf_beta_blocker
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(ltf_beta_blocker = as.character(ltf_beta_blocker)) %>%
  mutate(ltf_beta_blocker = factor(na_if(ltf_beta_blocker, ""), levels = c("Yes", "No, for medical reason", "No"))) %>%
  mutate(ltf_beta_blocker = fct_relevel(ltf_beta_blocker, "Yes", "No, for medical reason", "No")) # yes no # N

# ltf_ace_inhibitor_arb
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(ltf_ace_inhibitor_arb = as.character(ltf_ace_inhibitor_arb)) %>%
  mutate(ltf_ace_inhibitor_arb = factor(na_if(ltf_ace_inhibitor_arb, ""), levels = c("Yes", "No, for medical reason", "No"))) %>%
  mutate(ltf_ace_inhibitor_arb = fct_relevel(ltf_ace_inhibitor_arb, "Yes", "No, for medical reason", "No")) # yes no # N

# right_iliac_endpoint
EVAR_preprocess$right_iliac_endpoint <- fct_relevel(EVAR_preprocess$right_iliac_endpoint, "None","Common", "External, Intended", "External, Unintended") #N

# left_iliac_endpoint
EVAR_preprocess$left_iliac_endpoint <- fct_relevel(EVAR_preprocess$left_iliac_endpoint, "None","Common", "External, Intended", "External, Unintended") #N
  
```


### Variable Selection
Remove variables based on Josh's suggestions (02/26/2024)

```{r}

# Remove records with race: unknown/other, American Indian or Alaskan Native, Asian
EVAR_preprocess <- EVAR_preprocess %>%
  filter(race != "Unknown / Other") %>%
  filter(race != "American Indian or Alaskan Native" ) %>%
  filter(race != "Asian") %>% 
  filter(anesthesia != "Regional") %>%
  filter(discharge_status != "Dead") %>%
  droplevels()
  

variables_to_remove <- c(
  # Demographics
  "hispanic_or_latino",
  "physician",
  "renal_svs",
  "age_svs", 
  "height_cm", 
  "weight_kg", 
  "living_status", 
  
  # lab data
  "basophil_percent",
  "calcium",
  "chloride",
  "co2",
  "eosinophil_percent",
  "hemoglobin",
  "lymphocyte_percent",
  "mch",
  "mchc",
  "monocyte_percent",
  "sodium",
  "wbc",
  
  # Other
  "genetic_history",
  "pasc_none",
  "total_procedure_time",
  "iodinated_contrast",
  "prbc_in_or_or_preop",
  "right_iliac_endpoint",
  "left_iliac_endpoint",
  "right_iliac_graft_mfg_1",
  "left_iliac_graft_mfg_1",
  "transfusion_number_units_prbc",
  "lowest_hemoglobin",
  "highest_creatinine",
  "vital_status",
  "ltf_asa",
  "ltf_p2y12_antagonist",
  "ltf_statin",
  "ltf_beta_blocker",
  "ltf_ace_inhibitor_arb",
  "ltf_anticoagulant",
  "hematocrit",
  
  "survival_years",
  "survival_1yr",
  "survival_5yr")

EVAR_preprocess <- EVAR_preprocess[,!(names(EVAR_preprocess) %in% variables_to_remove)]
```


### Combining Variables

Combine variables
```{r}

EVAR_preprocess <- EVAR_preprocess %>%
  mutate(
    aortic_main_device = fct_collapse(as.factor(aortic_main_device),
                                           "Bifurcated renal fixation" = c("Bifurcated infra-renal", 
                                                                           "Bifurcated supra-renal fixation"),
                                           "Aorto-uni-iliac" = c("Aorto-uni-iliac, left", 
                                                                 "Aorto-uni-iliac, right")),
    
    proximal_aortic_extensions = fct_collapse(as.factor(proximal_aortic_extensions),
                                           "No" = c("None"),
                                           "Yes" = c("1", "2", "3")),
    
    number_right = fct_collapse(as.factor(number_right),
                                           "2+" = c("2", "3")),
    number_left = fct_collapse(as.factor(number_left),
                                           "2+" = c("2", "3")),
    
    iv_bp_support_post_op = fct_collapse(as.factor(iv_bp_support_post_op),
                                              "Yes" = c(">24 hrs postop", "Yes, < 4 hrs", "Yes, 4-24 hrs", "Yes")),
    
    pre_op_p2y12_antagonist = fct_collapse(as.factor(pre_op_p2y12_antagonist),
                                                   "No" = c("None", "No"),
                                                   "Yes" = c("Clopidogrel", "Ticagrelor","Prasugrel")),
    
    pre_op_beta_blocker = fct_collapse(as.factor(pre_op_beta_blocker),
                                                   "No" = c("No, for medical reason", "No"),
                                                   "Yes" = c("Pre-op 1-30 days", "Chronic > 30 days")),
    
    pre_op_chronic_anticoagulant = fct_collapse(as.factor(pre_op_chronic_anticoagulant),
                                                   "No" = c("None", "No, for medical reason"),
                                                   "Yes" = c("Rivaroxaban", "Warfarin", "Dabigatran", "Other")),
    
    discharge_p2y12_antagonist = fct_collapse(as.factor(discharge_p2y12_antagonist),
                                                   "No" = c("None", "No"),
                                                   "Yes" = c("Clopidogrel", "Ticagrelor","Prasugrel")),
    
    discharge_anticoagulant = fct_collapse(as.factor(discharge_anticoagulant),
                                                "No" = c("None", "No"),
                                                "Yes" = c("Rivaroxaban","Warfarin","Other","Dabigatran")),
    
    aortic_graft_manufacturer_1 = fct_collapse(as.factor(aortic_graft_manufacturer_1),
                                                "Other" = c("Other", "Medtronic", "Endologix")),
    
  # Combine right_internal_illiac and left_internal_illiac. 
  # Both have levels: "Coil Occlusion" "IFU" "Bell Bottom" "Amplatzer plug" "Branch graft" "Covered"
    internal_illiac_BellBottom = ifelse(
      right_internal_iliac == "Bell Bottom" | left_internal_iliac == "Bell Bottom", 1, 0),
    
    internal_illiac_BranchGraft = ifelse(
      right_internal_iliac == "Branch graft" | left_internal_iliac == "Branch graft", 1, 0),
    
    internal_illiac_CoiledAndCovered = ifelse(
      right_internal_iliac == "Coil Occlusion" | left_internal_iliac == "Coil Occlusion" | 
        right_internal_iliac == "Covered" & left_internal_iliac == "Covered" | 
        right_internal_iliac == "Amplatzer plug" | left_internal_iliac == "Amplatzer plug", 1, 0)) %>%
  mutate(number_right = fct_relevel(number_right, "0", "1", "2+")) %>%
  
  # right_illiac_adjunct.Stent.Graft and left coalesce
  mutate(iliac_adjunct = coalesce(right_iliac_adjunct, left_iliac_adjunct)) %>%
  mutate(left_internal_iliac = NULL,
         right_internal_iliac = NULL,
         right_iliac_adjunct = NULL,
         left_iliac_adjunct = NULL) %>%
  mutate(sac_regression_12m_cat = fct_collapse(sac_regression_12m_cat,
                                               "Not Regressed" = c("Stable", "Expansion")))

```



Now we generate a glimpse into EVAR_preprocess
```{r EVAR-preprocess-ff-glimpse}
EVAR_preprocess_glimpse <- ff_glimpse(EVAR_preprocess)
```




Remove cols and rows with too many missing values
- remove records with too many missing values (\>40%) 
- remove columns with too many missing values (\>20%)

Had to do this manually using EVAR_preprocess_glimpse

```{r}
cols_to_remove <- c("number_closure_devices_right",
                    "number_closure_devices_left",
                    "distal_endpoint_right",
                    "distal_endpoint_left",
                    "largest_sheath_size_right",
                    "largest_sheath_size_left",
                    "right_iliac_graft_length_1",
                    "right_iliac_graft_diameter_1",
                    "left_iliac_graft_length_1",
                    "left_iliac_graft_diameter_1")

EVAR_preprocess <- EVAR_preprocess[,!(names(EVAR_preprocess) %in% cols_to_remove)]

# For rows, there are no rows with >40% missing values
# Should return FALSE - there are no rows with more than 40% missing data
print(any(rowSums(is.na(EVAR_preprocess)) > 0.4 * length(EVAR_preprocess)))

```


### Pre-processing report

Generate a report about the data before any pre-processing steps like scaling, and imputation
explore is a nice pkg with function report(). Generates plots and summary stats for all vars in database.

```{r pre-process-report}
EVAR_pre_report_filename <- "Report_EVAR_Preprocess.html"
EVAR_preprocess_report <- report(EVAR_preprocess, 
                                 output_file = EVAR_pre_report_filename,
                                 output_dir = getwd())
```

### Demographics Table

Generate a table1
Finalfit has a function called summary_factorlist() for this
It includes numeric and categorical variables, despite the name...
We want to include the missing data

Stratify against our outcome variable: sac_regression_12m_cat

Currently, there are some warnings: Chi-sq test may be incorrect

```{r table1-demographics}

EVAR_preprocess_predictorsdf <- EVAR_preprocess %>%
  select(-sac_regression_12m_cat)

demographics_table1 <- EVAR_preprocess %>%
  summary_factorlist(dependent = "sac_regression_12m_cat", # outcome variable
  explanatory = names(.)[names(.) != "sac_regression_12m_cat"] , #predictors
  na_include = TRUE,
  na_include_dependent = TRUE,
  total_col = TRUE,
  add_col_totals = TRUE,
  p = TRUE,
  p_cont_para = "aov",
  p_cat = "fisher"
  )
```


### Missing Data Analysis
We want to impute some values. We should determine the nature of our missing data

#### Visualize missing data

```{r visualize-missing}
# Use VIM package
EVAR_preprocess_missing_plot <- aggr(EVAR_preprocess, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(EVAR_preprocess), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```

#### Missingness Pattern
Use md.pattern from mice pkg
We can also use missing_pattern() from finalfit

```{r missingness-pattern}
missingnesspatterndf <- md.pattern(EVAR_preprocess, plot = FALSE)

# num rows is the number of missing patterns
cat("Num of Missing Patterns: ", 
          nrow(missingnesspatterndf), "\n")
```


## PRE-PROCESS


Pipeline: Split -> Impute ->  Feature Selection -> Scale ->  One-hot Encode

### Split Data
Always split first :)

```{r split-data}
set.seed(42)

# split using caTools package
split_sample <- sample.split(EVAR_preprocess$race, 
                             # 70 - 30 split
                             SplitRatio = 0.7)

# Subset train and test data frames
train_df <- subset(EVAR_preprocess, split_sample == TRUE)
test_df <- subset(EVAR_preprocess, split_sample == FALSE)
```


### Imputation

Get a glimpse of training data
```{r train-ff-glimpse}
train_df_glimpse <- ff_glimpse(train_df)
```

We assume data missing at random (MAR)

The imputation strategy is to use missRanger - a fast multiple imputation method using randomForests
Literature shows it is better than standard MICE: 

Suh H, Song J.  A comparison of imputation methods using machine learning models.  CSAM 2023;30:331-341.  https://doi.org/10.29220/CSAM.2023.30.3.331

```{r imputation}

# missRanger

train_imputed <- missRanger(data =  train_df, 
                           # impute all variables using all variables except outcomes
                           formula = . ~ . -sac_regression_12m_cat - survival_1yr_censor - survival_5yr_censor - reintervention,
                           pmm.k = 3, num.trees = 100)

test_imputed <- missRanger(data =  test_df, 
                           # impute all variables using all variables except outcomes
                           formula = . ~ . -sac_regression_12m_cat - survival_1yr_censor - survival_5yr_censor - reintervention, 
                           pmm.k = 3, num.trees = 100)
```


### Ordinal Variables
```{r}
# To make sure ordering of each factor variable makes sense, we must investigate each to determine which need to reordered with fct_relevel
# Extract information about factor variables
ordinalfactorVars_info <- lapply(names(train_imputed), function(column_name) {
  column <- train_imputed[[column_name]]
  
  if (is.factor(column)) {
    levels_info <- levels(column)
    return(list(
      variable_name = column_name,
      num_levels = length(levels_info),
      levels = levels_info
    ))
  } else {
    return(NULL)  # Not a factor variable
  }
})

# Remove NULL elements (non-factor variables) from the list
ordinalfactorVars_info <- ordinalfactorVars_info[sapply(train_imputed, function(x) !is.null(x))]

# Print the information
for (info in ordinalfactorVars_info) {
  cat("Variable Name:", info$variable_name, "\n")
  cat("Number of Levels:", info$num_levels, "\n")
  cat("Levels:", paste(info$levels, collapse = "; "), "\n\n")
}
```

Based on the above, ordinal vars are:
dysrhy, functional_status, cad_symptoms, 
copd, diabetes, smoking, prior_cabg, prior_pci, stress_test, pre_op_p2y12_antagonist, pre_op_beta_blocker, pre_op_chronic_anticoagulant, ejection_fraction, aorta_neck_angle, neck_aaa_angle, discharge_p2y12_antagonist

Here we convert the ordinal variables to be numeric to preserve ordinality. It also helps to reduce dimensionality when we one-hot encode all the other categorical variables

```{r ordinal-vars}
# List of ordinal factor variables
ordinal_factors <- c("dysrhy", "functional_status", "cad_symptoms", "cvd", "cad_symptoms", "prior_chf", "copd", "diabetes", "dialysis", "smoking", "prior_cabg", "prior_pci", "prior_cea_cas", "prior_aneurysm_repair", "prior_major_amp", "stress_test", "ejection_fraction", "aorta_neck_angle", "neck_aaa_angle", "iliac_aneurysm")

# Convert each ordinal factor variable to numeric preserving ordinality
for (factor_var in ordinal_factors) {
  train_imputed[[factor_var]] <- as.numeric((train_imputed[[factor_var]]))
  test_imputed[[factor_var]] <- as.numeric((test_imputed[[factor_var]]))

}
```


### Scaling

```{r}

# Apply scaling to numerical columns in train dataframe
train_scaled <- train_imputed %>%
  mutate(across(where(is.numeric), as.numeric)) %>%  # Ensure all numeric columns are numeric
  preProcess(method = "range", cols = where(is.numeric)) %>%
  predict(train_imputed)

# Apply scaling to numerical columns in test dataframe
test_scaled <- test_imputed %>%
  mutate(across(where(is.numeric), as.numeric)) %>%  # Ensure all numeric columns are numeric
  preProcess(method = "range", cols = where(is.numeric)) %>%
  predict(test_imputed)

```


### One-hot encoding
We perform one-hot encoding for every categorical variable
Use dummyVars from caret

We also one-hot encode the outcome variable in order to transform the multi-class classification problem (3 levels: regression, stability and expansion) into three binary classification problems. Each binary outcome variable represents one of the classes versus the rest (often referred to as one-vs-rest or one-vs-all strategy

```{r one-hot-encode}
# fullRank TRUE ensures no linear dependencies induced between the columns
dummyEVAR <- dummyVars(" ~ .", data = train_scaled, fullRank=T, dummy_na = TRUE)
train_onehot <- data.frame(predict(dummyEVAR, newdata = train_scaled))
test_onehot <- data.frame(predict(dummyEVAR, newdata = test_scaled))
```

### NZV for one-hot encode

Perform nzv again as we have one-hot encoded categorical variables. Some have no variance!

Remove variables with zero variance
```{r zero-variance-2-vars}

nzv2 <- nearZeroVar(train_onehot, saveMetrics= T)

# Shortlist of NZV features
nzv_to_remove2 <- nzv2 %>%
  filter(nzv == TRUE) %>%
  mutate(col_names = rownames(.)) %>%
  select(col_names)
    
# Let's remove our NZV variables
train_final <- train_onehot %>% 
  select(-pull(nzv_to_remove2, col_names))

test_final <- test_onehot  %>% 
 select(-pull(nzv_to_remove2, col_names))
```



We have finished preprocessing :)
```{r}
EVAR_post_report_filename <- "Report_EVAR_Postprocess.html"
EVAR_postprocess_report <- report(train_final, 
                                 output_file = EVAR_post_report_filename,
                                 output_dir = getwd())
```


```{r correlation-matrix}
# Calculate correlation matrix
correlation_matrix_sacregression <- cor(train_final[, -which(names(train_final) == "sac_regression_12m_cat.Regression")])

# Visualize correlation matrix as a heatmap
heatmap(correlation_matrix_sacregression)
```


## MODEL TRAINING

### Setting up
```{r model-train}


train_sacreg <- train_final %>%
  mutate(sac_regression_12m_cat.Regression = 
           as.factor(sac_regression_12m_cat.Regression),
         survival_1yr_censor.1 = 
           as.factor(survival_1yr_censor.1),
         survival_5yr_censor.1 = 
           as.factor(survival_5yr_censor.1),
         reintervention.Yes = 
           as.factor(reintervention.Yes))

test_sacreg <- test_final %>%
  mutate(sac_regression_12m_cat.Regression = 
           as.factor(sac_regression_12m_cat.Regression),
         survival_1yr_censor.1 = 
           as.factor(survival_1yr_censor.1),
         survival_5yr_censor.1 = 
           as.factor(survival_5yr_censor.1),
         reintervention.Yes = 
           as.factor(reintervention.Yes))

levels(train_sacreg$sac_regression_12m_cat.Regression) <- c("X0", "X1")
levels(test_sacreg$sac_regression_12m_cat.Regression) <- c("X0", "X1")

levels(train_sacreg$survival_1yr_censor.1) <- c("X0", "X1")
levels(test_sacreg$survival_1yr_censor.1) <- c("X0", "X1")

levels(train_sacreg$survival_5yr_censor.1) <- c("X0", "X1")
levels(test_sacreg$survival_5yr_censor.1) <- c("X0", "X1")

levels(train_sacreg$reintervention.Yes) <- c("X0", "X1")
levels(test_sacreg$reintervention.Yes) <- c("X0", "X1")


other_outcome_vars <- c("reintervention.Yes", 
                         "survival_5yr_censor.1",
                         "sac_regression_12m_cat.Regression")

train_sacreg <- train_sacreg %>%
   select(-all_of(other_outcome_vars))

test_sacreg <- test_sacreg %>%
   select(-all_of(other_outcome_vars))
 
ml_outcome <- "survival_1yr_censor.1"

```

### trainControl
```{r}
repeatedcv_trControl <- trainControl(method = "repeatedcv", 
                                       number = 5, 
                                       repeats = 5, # 5-fold ; 5 repeats
                                       classProbs = TRUE, # to get class probabilities for ROC curve
                                       summaryFunction = twoClassSummary, # for binary classification
                                       savePredictions = TRUE, # Save predictions for metrics calculation
                                       returnData = FALSE, # Do not return the resampled data
                                       returnResamp = "final", # Only return the final resample result
                                       selectionFunction = "best", # Use the best model based on AUC
                                       allowParallel = TRUE) # Enable parallel processing if available

```


### Logistic Regression
```{r logisticreg}

start_time <- Sys.time()

# train model
LR <- train(reintervention.Yes ~ .,
            data = train_sacreg,
               method = "glm",
               family = "binomial",
               trControl = repeatedcv_trControl,
               metric = "ROC" # Increase max iterations
               )

# Make predictions on the test set
LRpred <- predict(LR,
                  s = LR$bestTune$lambda, # choose the best lambda
                  newdata = test_sacreg %>% select(-reintervention.Yes), # use the test set
                  type = "prob")

LRROC <- roc(test_sacreg$reintervention.Yes, LRpred$X1)

total_time <- Sys.time() - start_time
cat("LogisticRegression time", total_time, "\n",
    "AUC", LRROC$auc, "\n")


# Try elastic regression or LASSO
# Find subset of variables
# 
```


### RF
```{r rf}
# Random Forest Model
start_time <- Sys.time()


train_sacreg <- ROSE(survival_1yr_censor.1 ~ ., data = train_sacreg, N = 1000, seed = 42)$data
# specify tuning grid for optimum hyperparameters
RFgrid <- expand.grid(mtry = 2:4, 
                      splitrule = "gini", 
                      min.node.size = c(10,20))

levels(train_sacreg$survival_1yr_censor.1) <- c("X0", "X1")

# train RF model
RF <- train(survival_1yr_censor.1 ~ .,
            data = train_sacreg,
            method = "ranger",
            trControl = repeatedcv_trControl,
            tuneGrid = RFgrid,
            metric = "ROC")

# predict on test set
RFpred <- predict(RF, newdata = test_sacreg %>% select(-survival_1yr_censor.1), # use the test set
                         type = "prob")

RFROC <- roc(test_sacreg$survival_1yr_censor.1, RFpred$X1)

total_time <- Sys.time() - start_time
cat("RF time", total_time, "\n",
    "AUC", RFROC$auc, "\n")
```

### XGBoost Tree

Takes a while to run. XGBoost can be computationally expensive

```{r xgboost}
# XGBoostTree Model
start_time <- Sys.time()

# specify tuning grid for optimum hyperparameters
XGBgrid <- expand.grid(nrounds = (1:5)*50,
                       max_depth = 2:5,
                       eta = c(0.4,0.1,0.001),
                       min_child_weight = c(1,5,10),
                       subsample = c(0.5,0.7,0.9,1),
                       gamma = c(0,0.1,1,2),
                       colsample_bytree = c(0.5,0.7,0.9,1))
# train RF model
XGB <- train(sac_regression_12m_cat.Regression ~ .,
            data = train_lasso,
            method = "xgbTree",
            trControl = repeatedcv_trControl,
            # tuneGrid = XGBgrid,
            metric = "ROC")

# predict on test set
XGBpred <- predict(XGB, newdata = test_lasso %>% select(-sac_regression_12m_cat.Regression), # use the test set
                         type = "prob")

XGBROC <- roc(test_lasso$sac_regression_12m_cat.Regression, XGBpred$X1)

total_time <- Sys.time() - start_time
cat("XGB time", total_time, "\n",
    "AUC", XGBROC$auc, "\n")
```


### Naive Bayes
```{r naive-bayes}
# Naive Bayes Model

start_time <- Sys.time()
# specify tuning grid for optimum hyperparameters
NBgrid <- expand.grid(
  laplace = c(0, 0.5, 1.0), 
  usekernel = c(TRUE,FALSE), 
  adjust = c(0, 0.5, 1.0))
# train RF model
NB <- train(reintervention.Yes ~ .,
            data = train_sacreg,
            method = "naive_bayes",
            trControl = repeatedcv_trControl,
            tuneGrid = NBgrid,
            metric = "ROC")

# predict on test set
NBpred <- predict(NB, newdata = test_sacreg %>% select(-reintervention.Yes), # use the test set
                         type = "prob")

NBROC <- roc(test_sacreg$reintervention.Yes, NBpred$X1)

total_time <- Sys.time() - start_time
cat("NB time", total_time, "\n",
    "AUC", NBROC$auc, "\n")
```


### Support Vector Machines
```{r svm}
# SVM model
start_time <- Sys.time()

# specify tuning grid for optimum hyperparameters
SVMgrid <- expand.grid(sigma = c(0.01, 0.05, 0.1, 1),
                          C = c(0.01, 0.05, 0.1, 1))
# train RF model
SVM <- train(reintervention.Yes ~ .,
            data = train_sacreg,
            method = "svmRadial",
            trControl = repeatedcv_trControl,
            tuneGrid = SVMgrid,
            metric = "ROC")

# predict on test set
SVMpred <- predict(SVM, newdata = test_sacreg %>% select(-reintervention.Yes), # use the test set
                         type = "prob")

SVMROC <- roc(test_sacreg$reintervention.Yes, SVMpred$X1)

total_time <- Sys.time() - start_time
cat("SVM time", total_time, "\n",
    "AUC", SVMROC$auc, "\n")

```


### Variable Importance

```{r}
vimp <- varImp(NB,  scale = FALSE)
print(vimp)
```



## PLOTS

```{r}

plot_roc_comparison <- function(roc1, roc2, 
                                roc1_color = "red", roc2_color = "blue",
                                title = "ROC Curve Comparison") {
  # Convert ROC curves to data frames
  roc1_df <- data.frame(
    FPR = 1 - roc1$specificities,
    TPR = roc1$sensitivities
  )
  
  roc2_df <- data.frame(
    FPR = 1 - roc2$specificities,
    TPR = roc2$sensitivities
  )
  
  # Calculate AUC values
  auc1 <- roc1$auc
  auc2 <- roc2$auc
  
  # Calculate confidence intervals for ROC curves
  ci1 <- ci.se(roc1, specificities=seq(0, 1, l=25))
  ci2 <- ci.se(roc2, specificities=seq(0, 1, l=25))
  
  dat.ci1 <- data.frame(x = as.numeric(rownames(ci1)),
                     lower = ci1[, 1],
                     upper = ci1[, 3])
  
  dat.ci2 <- data.frame(x = as.numeric(rownames(ci2)),
                     lower = ci2[, 1],
                     upper = ci2[, 3])
  
  
  # Plot ROC curves using ggplot2
  plot <- ggplot() +
    geom_line(data = roc1_df, aes(x = FPR, y = TPR), 
              color = roc1_color, linetype = "solid") +
    geom_line(data = roc2_df, aes(x = FPR, y = TPR), 
              color = roc2_color, linetype = "solid") +
    geom_ribbon(data = dat.ci2, aes(x = 1 - x, ymin = lower, ymax = upper), fill = "steelblue", alpha= 0.2) +
    geom_abline(slope = 1, intercept = 0, linetype = "dotted", color = "black") + # Add diagonal line for reference
    labs(x = "False Positive Rate", y = "True Positive Rate", title = title) +
    annotate("text", x = 0.8, y = 0.13, label = paste("AUC:", round(auc1, 3)), color = roc1_color, size = 3, hjust = 0, vjust = 0) +
    annotate("text", x = 0.8, y = 0.05, label = paste("AUC:", round(auc2, 3)), color = roc2_color, size = 3, hjust = 0, vjust = 0) +
    theme_minimal()
  
  return(plot)
}



plot1 <- plot_roc_comparison(LRROC, RFROC, title = "Random Forest vs. LR")
plot2 <- plot_roc_comparison(LRROC, XGBROC, title = "XGBoost vs. LR")
plot3 <- plot_roc_comparison(LRROC, NBROC, title = "Naive Bayes vs. LR")
plot4 <- plot_roc_comparison(LRROC, SVMROC, title = "SVM vs. LR")

super_plot <- grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)

```

```{r}
ggsave("sac_reg.png", plot = super_plot, dpi = 300, height = 6, width = 7.5)
```

## Elastic Nets

### 1 Year Survival

#### Cross validation
```{r}
# Prepare your data
LassoX <- model.matrix(survival_1yr_censor.1 ~ ., data = train_sacreg)
Lassoy <- train_sacreg$survival_1yr_censor.1

# Perform 10-fold cross-validation to select lambda
lambdas_to_try <- 10^seq(-4, 4, length.out = 100)

# Setting alpha = 1 for lasso; alpha = 0 for ridge
cv8 <- cv.glmnet(LassoX, Lassoy, alpha = 0.8, lambda = lambdas_to_try,
                  standardize = TRUE, nfolds = 5, type.measure = "mse",
                  family = "binomial")
cv9 <- cv.glmnet(LassoX, Lassoy, alpha = 0.9, lambda = lambdas_to_try,
                  standardize = TRUE, nfolds = 5, type.measure = "mse",
                  family = "binomial")
cv95 <- cv.glmnet(LassoX, Lassoy, alpha = 0.95, lambda = lambdas_to_try,
                 standardize = TRUE, nfolds = 5, type.measure = "mse",
                 family = "binomial")
cv1 <- cv.glmnet(LassoX, Lassoy, alpha = 1, lambda = lambdas_to_try,
                 standardize = TRUE, nfolds = 5, type.measure = "mse",
                 family = "binomial")

# Plot cross-validation results
par(mfrow=c(2,2))
plot(cv8);plot(cv9);plot(cv95);plot(cv1)

# Compare the solution paths
par(mfrow=c(2,2))
plot(glmnet(LassoX, Lassoy, alpha = 0.8, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 0.9, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 0.95, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 1, family = "binomial"),xvar="lambda")

coef(cv95)


```

```{r}

# Fit the logistic regression model with Lasso regularization
lasso_model <- glmnet(LassoX, Lassoy,
                         family = "binomial",
                      alpha = 0.95,
                      nlambda = 100)

# Choose the optimal lambda (regularization parameter) using cross-validation
best_lambda <- lasso_model$lambda.min

# Refit the model using the selected lambda
lasso_model_final <- lasso_model <- glmnet(LassoX, Lassoy,
                         family = "binomial",
                      alpha = 0.95,
                      lambda = best_lambda)

# Extract coefficients from the model
coefficients <- coef(lasso_model_final)

# Extract coefficients from the model
coefficients <- as.data.frame(as.matrix(coef(lasso_model_final)))

# Convert to data frame with proper column names
coefficients_df <- rownames_to_column(coefficients, var = "Variable")

coefficients_df <- coefficients_df %>%
  filter(s0 != 0)

ggplot(coefficients_df, aes(x = Variable, y = s0)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(x = "Variables", y = "Coefficients", title = "Lasso Regression Coefficients") +
  theme_minimal()
```




### Sac Regression

#### Cross validation
```{r}
# Prepare your data
LassoX <- model.matrix(sac_regression_12m_cat.Regression ~ ., data = train_sacreg)
Lassoy <- train_sacreg$sac_regression_12m_cat.Regression

# Perform 10-fold cross-validation to select lambda
lambdas_to_try <- 10^seq(-4, 4, length.out = 100)

# Setting alpha = 1 for lasso; alpha = 0 for ridge
cv8 <- cv.glmnet(LassoX, Lassoy, alpha = 0.8, lambda = lambdas_to_try,
                  standardize = TRUE, nfolds = 5, type.measure = "mse",
                  family = "binomial")
cv9 <- cv.glmnet(LassoX, Lassoy, alpha = 0.9, lambda = lambdas_to_try,
                  standardize = TRUE, nfolds = 5, type.measure = "mse",
                  family = "binomial")
cv95 <- cv.glmnet(LassoX, Lassoy, alpha = 0.95, lambda = lambdas_to_try,
                 standardize = TRUE, nfolds = 5, type.measure = "mse",
                 family = "binomial")
cv1 <- cv.glmnet(LassoX, Lassoy, alpha = 1, lambda = lambdas_to_try,
                 standardize = TRUE, nfolds = 5, type.measure = "mse",
                 family = "binomial")

# Plot cross-validation results
par(mfrow=c(2,2))
plot(cv8);plot(cv9);plot(cv95);plot(cv1)

# Compare the solution paths
par(mfrow=c(2,2))
plot(glmnet(LassoX, Lassoy, alpha = 0.8, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 0.9, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 0.95, family = "binomial"),xvar="lambda");
plot(glmnet(LassoX, Lassoy, alpha = 1, family = "binomial"),xvar="lambda")

coef(cv95)


```

```{r}

# Fit the logistic regression model with Lasso regularization
lasso_model <- glmnet(LassoX, Lassoy,
                         family = "binomial",
                      alpha = 0.95,
                      nlambda = 100)

# Choose the optimal lambda (regularization parameter) using cross-validation
best_lambda <- lasso_model$lambda.min

# Refit the model using the selected lambda
lasso_model_final <- lasso_model <- glmnet(LassoX, Lassoy,
                         family = "binomial",
                      alpha = 0.95,
                      lambda = best_lambda)

# Extract coefficients from the model
coefficients <- coef(lasso_model_final)

# Extract coefficients from the model
coefficients <- as.data.frame(as.matrix(coef(lasso_model_final)))

# Convert to data frame with proper column names
coefficients_df <- rownames_to_column(coefficients, var = "Variable")

coefficients_df <- coefficients_df %>%
  filter(s0 != 0)

ggplot(coefficients_df, aes(x = Variable, y = s0)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(x = "Variables", y = "Coefficients", title = "Lasso Regression Coefficients") +
  theme_minimal()
```






```{r}
lasso_vars <- c("proc_year", "age_at_procedure", "cad_symptoms","copd","prior_pci"             ,"prior_arterial_pvi.Yes",  "anion_gap"                            
,"creatinine", "glucose"                              
,"mono_number_k_ul", "platelets"                            
,"potassium", "rdw"                                  
,"urea_nitrogen" ,"pre_op_hemoglobin_g_l"                
, "pre_op_asa.Yes" ,"pre_op_ace_inhibitor_arb.Yes"         
, "unfit_for_open_aaa_repair.Yes"         ,"rt_int_iliac_diameter"                
, "lt_int_iliac_diameter","rt_distal_seal_zone_length"           
, "anesthesia.General","crystalloid"                          
, "access_right.Open.femoral..transverse" ,"aortic_graft_manufacturer_1.Cook"     
,"number_right.1","number_right.2."                      
, "number_left.2.","discharge_statin.Yes","years_quit_smoking",

"sac_regression_12m_cat.Regression")

train_lasso <- train_sacreg %>%
  select(all_of(lasso_vars))
test_lasso <- test_sacreg %>%
  select(all_of(lasso_vars))
```






### LR with Elastic Nets
```{r logisticreg-LASSO}

start_time <- Sys.time()

lambda_grid <- expand.grid(alpha = 1, lambda= seq(0.001, 3, length = 200))

# train model
LRLasso <- train(sac_regression_12m_cat.Regression ~ .,
                 data = train_sacreg,
                 method = "glmnet",
                 family = "binomial",
                 trControl = repeatedcv_trControl,
                 tuneGrid = lambda_grid,
                 metric = "ROC"
                 )
# Access the coefficients of the selected model
lasso_coefficients <- coef(LRLasso$finalModel, s = LRLasso$bestTune$lambda)
# Plot the coefficient path
coefficient_plot <- plot(LRLasso$finalModel, xvar = "lambda", label = TRUE)

# Make predictions on the test set
LRLassopred <- predict(LRLasso,
                  s = LRLasso$bestTune$lambda, # choose the best lambda
                  newdata = test_sacreg %>% select(-sac_regression_12m_cat.Regression), # use the test set
                  type = "prob")

LRLassoROC <- roc(test_sacreg$sac_regression_12m_cat.Regression, LRLassopred$X1)

total_time <- Sys.time() - start_time
cat("LogisticRegression with Lasso time", total_time, "\n",
    "AUC", LRLassoROC$auc, "\n")


# Try elastic regression or LASSO
# Find subset of variables
# 
```



# END
```{r}

```

\`\`\`
