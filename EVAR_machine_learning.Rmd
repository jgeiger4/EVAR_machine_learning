---
title: "EVAR_machine_learning"
author: "Joshua Geiger and Mohammed Mehdi Shahid"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---


Hey Mehdi,

Thanks for getting this started. The rds dataset that i provided is a pretty good clean start. The variable that we will be attempting to predict is sac_regression_12m_cat. This variable states weather The Shins aortic aneurysms sac regressed states stable or increased in size at the one-year mark. I had to do a bit of reformatting of all of the data in order to calculate this appropriately given the variability in the CT scan dates and sizes. I am confident this variable is accurate at the moment. 

There are variables within the data set that are incomplete and perhaps chart reviewing to finish collecting some of this data will be important. Particularly the first couple of patients were recorded before all of the VQI variables were established and so there is some missing data there. Additionaly, the last 20 some patients I recently extracted from the VQI and so variables we manually extracted from the chart have not be collected yet. Baqir and I can help out with this. Baqir has also submitted a request for the lab values for these last 20 some patients. In addition we will be obtaining dates of death for the entire data set. I think doing an additional analysis using similar methods on survival, either length of survival or survival at 5 years will also be interesting.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup}
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")

#Install relevant libraries using pacman (i.e. package manager)

# Use pacman to load add-on packages as desired
pacman::p_load(pacman, rio, dplyr, forcats, ggplot2, tidyverse, mice, caret)
```

```{r load-data}
EVARSourcedir <- "~/Desktop/EVAR/EVAR_cleaned_filtered_11_12_23.rds"
EVAR <- readRDS(EVARSourcedir)
```

```{r correct-errors}
#Correct errors in the EVAR dataframe
EVAR[ which(EVAR$primprocid == 798089), "height_cm"] <- 188.00
EVAR[ which(EVAR$primprocid == 798089), "bmi"] <- 32.7
```


# DATA PREPROCESSING

Remove cols and rows with too many missing values
-   remove records with too many missing values (\>40%)
-   remove columns with too many missing values (\>20%)

```{r}

# Remove records with too many missing values
EVAR_preprocess <- EVAR_merged[complete.cases(EVAR_merged) | rowSums(is.na(EVAR_merged)) <= ncol(EVAR_merged) * 0.4, ] # 0.4 denotes removing records with more than 40% missing values

# Remove columns with too many missing values
EVAR_preprocess <- EVAR_preprocess[, colMeans(is.na(EVAR_preprocess)) <= nrow(EVAR_preprocess) * 0.2] # 20%


# Remove rows 430 to 461 as they are not complete yet
EVAR_preprocess <- EVAR_preprocess[-(430:461), ]
```

Remove unnecessary or uninformative columns
```{r}
EVAR_preprocess$zip_postal_code <- NULL

#removing smoking quit date as I don't know how to work with this data type with ML for now....
EVAR_preprocess$quit_smoking_date <- NULL
```

Change column data types

When converting to factors make sure the ordering makes sense.For example factor levels for smoking might look something like never, quit, current. Changing the order to something like quit, current, never, could very much mess with the analysis if these factors are considered as ordinal variables, which they often are. can use fct_relevel to change these

```{r}
# Convert all character columns to factors
EVAR_preprocess <- EVAR_preprocess %>%
  mutate_if(is.character, as.factor)

```

'No' and 'Yes' are mostly nominal, but for consistency, we can reorder
all factor variables with 'No' and 'Yes' to be No for level 1 and Yes
for level 2

```{r}
# Identify factor variables with 'No' and 'Yes' levels
no_yes_factors <- EVAR_preprocess %>%
  select(where(is.factor)) %>%
  keep(~ length(levels(.)) == 2 && all(c("No", "Yes") %in% levels(.)))

# Reorder the levels for 'No' as level 1 and 'Yes' as level 2
EVAR_preprocess <- EVAR_preprocess %>%
  mutate(across(all_of(names(no_yes_factors)), ~fct_relevel(., "No", "Yes")))

```

```{r factor-variables}
# To make sure ordering of each factor variable makes sense, we must investigate each to determine which need to reordered with fct_relevel
# Extract information about factor variables
factorVars_info <- lapply(names(EVAR_preprocess), function(column_name) {
  column <- EVAR_preprocess[[column_name]]
  
  if (is.factor(column)) {
    levels_info <- levels(column)
    return(list(
      variable_name = column_name,
      num_levels = length(levels_info),
      levels = levels_info
    ))
  } else {
    return(NULL)  # Not a factor variable
  }
})

# Remove NULL elements (non-factor variables) from the list
factorVars_info <- factorVars_info[sapply(factorVars_info, function(x) !is.null(x))]

# Print the information
for (info in factorVars_info) {
  cat("Variable Name:", info$variable_name, "\n")
  cat("Number of Levels:", info$num_levels, "\n")
  cat("Levels:", paste(info$levels, collapse = "; "), "\n\n")
}
```

Based on the above output, we choose which variables to reorder.
Variables that need to be reordered: cvd, prior_chf, dysrhythmia,
diabetes, dialysis, smoking, prior_pci, prior_cea_cas,
prior_aneurysm_repair, stress_test,pre_op_p2y12_antagonist,
pre_op_beta_blocker, pre_op_chronic_anticoagulant, ejection_fraction,
aorta_neck_angle, neck_aaa_angle, anesthesia, access_right, access_left,
right_iliac_adjunct, left_iliac_adjunct, proximal_aortic_extensions,
right_iliac_endpoint, left_iliac_endpoint, number_right,
distal_endpoint_right, number_left, distal_endpoint_left,
iv_bp_support_post_op, discharge_status

aortic_graft_length_1 needs some error fixes and then convert to num
right_iliac_graft_diameter_1 convert to num "right_iliac_graft_length_1"
and "left_iliac_graft_length_1" convert to num - has this 'Other' value





Hist visualization for numeric variables BEFORE imputation. Before we
impute missing data, we must visualize distributions of all numeric
variables and see if they change drastically with our imputation
strategy

Hist visualization for numeric variables BEFORE imputation.
Before we impute missing data, we must visualize distributions of all numeric variables and see if they change drastically with our imputation strategy

```{r}
# Extract column names (assuming the variables are numeric)
numeric_vars <- sapply(EVAR_preprocess, is.numeric)

# Set up a multi-plot layout
par(mfrow = c(2, 4), cex.main = 0.8, cex.lab = 0.6)  # Adjust the layout as needed

# Create histograms for all numeric variables pre imputation
preimputationHist <- for (var in names(EVAR_preprocess)[numeric_vars]) {
  hist(EVAR_preprocess[[var]], main = var, xlab = var, col = "lightblue", border = "black")
}

# Reset the layout to default
par(mfrow = c(1, 1),cex.main = 1, cex.lab = 1)
```

#### DATA SPLITTING

Note to future Mehdi: make sure you do NOT perform any feature selection
or rescaling on the entire dataset. These steps must happen for each
cross validation sequence so as to avoid data leakage. Here we shuffle
then split to create a hold out set. Each preprocessing step will be
done for both the train and test set to avoid data leakage

```{r}

set.seed(42)
train_percentage <- 0.8

# shuffle dataset
EVAR_preprocess <- EVAR_preprocess[sample(nrow(EVAR_preprocess)),]

indices <- createDataPartition(EVAR_preprocess$primprocid,
                               p = train_percentage,
                               list = FALSE)

# remove primprocid column as we no longer need it
EVAR_preprocess$primprocid <- NULL

trainSet <- EVAR_preprocess[indices, ]
testSet <- EVAR_preprocess[-indices, ]
```

#### DATA IMPUTATION

11. Numeric variables imputation.

The imputation strategy is to use MICE (Multivariate Imputation via Chained Equations) for numeric variables We assume data is missing at random (MAR)

```{r}

```
